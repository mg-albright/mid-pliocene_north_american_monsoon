{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f189334-2d82-4019-a4e0-1442604635f3",
   "metadata": {},
   "source": [
    "## Function to count the number of unique storm occurrences within TempestExtremes tracking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5c5e7c-7a62-48ef-b647-fedb702dafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02025c02-1927-4728-8d51-1ee9059d2789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/glade/work/malbright/final_nam_manuscript_files/mcs/pliocene/\"\n",
    "ds = (\n",
    "    xr.open_dataset(path + \"mcs_tracks_Plio_global_JJ.nc.compressed.nc\")\n",
    "    .sel(lat=slice(5, 45))\n",
    "    .sel(lon=slice(235, 280))\n",
    "    # .load()\n",
    ")\n",
    "\n",
    "years = np.unique(ds.time.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fce89b6-bfd0-4a1f-9c09-fc6618f59391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 34...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 35...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 36...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 37...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 38...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 39...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 40...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 41...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 42...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 43...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 44...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 45...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 46...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 47...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 48...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 49...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 50...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 51...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 52...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 53...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 54...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 55...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 56...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 57...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 58...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n",
      "Processing year 59...\n",
      "    Reshaping...\n",
      "    Processing pixels...\n",
      "    Saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(f\"Processing year {year}...\")\n",
    "    ds_year = ds.sel(time=f\"00{year}\")\n",
    "    mcs_prob = ds_year[\"MCS_PRECT\"]\n",
    "\n",
    "    unique_id_counts = np.zeros((ds_year.dims[\"lat\"], ds_year.dims[\"lon\"]), dtype=int)\n",
    "\n",
    "    # Flatten the time dimension and reshape it to time by lat by lon\n",
    "    print(\"    Reshaping...\")\n",
    "    reshaped_mcs_prob = mcs_prob.values.reshape(ds_year.dims[\"time\"], -1)\n",
    "\n",
    "    # Iterate over each pixel\n",
    "    print(\"    Processing pixels...\")\n",
    "    for lat_idx in range(ds_year.dims[\"lat\"]):\n",
    "        for lon_idx in range(ds_year.dims[\"lon\"]):\n",
    "            # Get all IDs for this specific pixel across time\n",
    "            pixel_ids = reshaped_mcs_prob[:, lat_idx * ds_year.dims[\"lon\"] + lon_idx]\n",
    "            # Count the unique IDs, ignoring the nan values\n",
    "            unique_ids = np.unique(pixel_ids[~np.isnan(pixel_ids)])\n",
    "            unique_id_counts[lat_idx, lon_idx] = len(unique_ids)\n",
    "\n",
    "    # Create a DataArray for the count of unique IDs\n",
    "    unique_id_counts_da = xr.DataArray(\n",
    "        unique_id_counts,\n",
    "        dims=[\"lat\", \"lon\"],\n",
    "        coords={\"lat\": ds[\"lat\"], \"lon\": ds[\"lon\"]},\n",
    "        name=\"unique_id_counts_climatology\",\n",
    "    )\n",
    "\n",
    "    # Save to a new NetCDF file\n",
    "    unique_id_counts_da.to_netcdf(f\"{path}mcs_counts_Plio_global_JJ_00{year}.nc\")\n",
    "    print(\"    Saved!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4e94a-ea18-4e2d-9ab4-895dad5b3802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2022b",
   "language": "python",
   "name": "npl-2022b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
